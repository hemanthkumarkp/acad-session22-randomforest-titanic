{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import csv as csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\hemanthkumar.k'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train = pd.read_csv('./data/train.csv')\n",
    "test = pd.read_csv('./data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of the features we will eventually want for our model\n",
    "features = ['Age', 'SibSp','Parch','Fare','male','embarked_Q','embarked_S','Pclass_2', 'Pclass_3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an encoder\n",
    "sex_encoder = preprocessing.LabelEncoder()\n",
    "\n",
    "# Fit the encoder to the train data so it knows that male = 1\n",
    "sex_encoder.fit(train['Sex'])\n",
    "\n",
    "# Apply the encoder to the training data\n",
    "train['male'] = sex_encoder.transform(train['Sex'])\n",
    "\n",
    "# Apply the encoder to the training data\n",
    "test['male'] = sex_encoder.transform(test['Sex'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Embarked training feature into dummies using one-hot\n",
    "# and leave one first category to prevent perfect collinearity\n",
    "train_embarked_dummied = pd.get_dummies(train[\"Embarked\"], prefix='embarked', drop_first=True)\n",
    "\n",
    "# Convert the Embarked test feature into dummies using one-hot\n",
    "# and leave one first category to prevent perfect collinearity\n",
    "test_embarked_dummied = pd.get_dummies(test[\"Embarked\"], prefix='embarked', drop_first=True)\n",
    "\n",
    "# Concatenate the dataframe of dummies with the main dataframes\n",
    "train = pd.concat([train, train_embarked_dummied], axis=1)\n",
    "test = pd.concat([test, test_embarked_dummied], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Pclass training feature into dummies using one-hot\n",
    "# and leave one first category to prevent perfect collinearity\n",
    "train_Pclass_dummied = pd.get_dummies(train[\"Pclass\"], prefix='Pclass', drop_first=True)\n",
    "\n",
    "# Convert the Pclass test feature into dummies using one-hot\n",
    "# and leave one first category to prevent perfect collinearity\n",
    "test_Pclass_dummied = pd.get_dummies(test[\"Pclass\"], prefix='Pclass', drop_first=True)\n",
    "\n",
    "# Concatenate the dataframe of dummies with the main dataframes\n",
    "train = pd.concat([train, train_Pclass_dummied], axis=1)\n",
    "test = pd.concat([test, test_Pclass_dummied], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object\n",
    "age_imputer = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "\n",
    "# Fit the imputer object on the training data\n",
    "age_imputer.fit(train['Age'].values.reshape(-1, 1))\n",
    "\n",
    "# Apply the imputer object to the training and test data\n",
    "train['Age'] = age_imputer.transform(train['Age'].values.reshape(-1, 1))\n",
    "test['Age'] = age_imputer.transform(test['Age'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an imputer object\n",
    "fare_imputer = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "\n",
    "# Fit the imputer object on the training data\n",
    "fare_imputer.fit(train['Fare'].values.reshape(-1, 1))\n",
    "\n",
    "# Apply the imputer object to the training and test data\n",
    "train['Fare'] = fare_imputer.transform(train['Fare'].values.reshape(-1, 1))\n",
    "test['Fare'] = fare_imputer.transform(test['Fare'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary containing all the candidate values of the parameters\n",
    "parameter_grid = dict(n_estimators=list(range(1, 5001, 1000)),\n",
    "                      criterion=['gini','entropy'],\n",
    "                      max_features=list(range(1, len(features), 2)),\n",
    "                      max_depth= [None] + list(range(5, 25, 1)))\n",
    "\n",
    "# Creata a random forest object\n",
    "random_forest = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "\n",
    "# Create a gridsearch object with 5-fold cross validation, and uses all cores (n_jobs=-1)\n",
    "clf = GridSearchCV(estimator=random_forest, param_grid=parameter_grid, cv=2, verbose=1, n_jobs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest.accurecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 840 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  6.4min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 14.3min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 42.1min\n",
      "[Parallel(n_jobs=10)]: Done 1680 out of 1680 | elapsed: 57.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 840 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  6.3min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 15.7min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 27.0min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 41.8min\n",
      "[Parallel(n_jobs=10)]: Done 1680 out of 1680 | elapsed: 56.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 840 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=10)]: Done 430 tasks      | elapsed: 13.7min\n",
      "[Parallel(n_jobs=10)]: Done 780 tasks      | elapsed: 24.6min\n",
      "[Parallel(n_jobs=10)]: Done 1230 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=10)]: Done 1680 out of 1680 | elapsed: 56.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores: [0.77104377 0.83501684 0.82154882]\n",
      "Mean of score: 0.8092031425364757\n",
      "Variance of scores: 0.0007583000474882243\n"
     ]
    }
   ],
   "source": [
    "# Nest the gridsearchCV in a 3-fold CV for model evaluation\n",
    "cv_scores = cross_val_score(clf, train[features], train['Survived'])\n",
    "\n",
    "# Print results\n",
    "print('Accuracy scores:', cv_scores)\n",
    "print('Mean of score:', np.mean(cv_scores))\n",
    "print('Variance of scores:', np.var(cv_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 840 candidates, totalling 1680 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=10)]: Done  30 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=10)]: Done 180 tasks      | elapsed:  5.9min\n"
     ]
    }
   ],
   "source": [
    "# Retrain the model on the whole dataset\n",
    "clf.fit(train[features], train['Survived'])\n",
    "\n",
    "# Predict who survived in the test dataset\n",
    "predictions = clf.predict(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
